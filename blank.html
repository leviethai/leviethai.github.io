<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
      <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Free Bootstrap Admin Template : Binary Admin</title>
	<!-- BOOTSTRAP STYLES-->
    <link href="assets/css/bootstrap.css" rel="stylesheet" />
     <!-- FONTAWESOME STYLES-->
    <link href="assets/css/font-awesome.css" rel="stylesheet" />
        <!-- CUSTOM STYLES-->
    <link href="assets/css/custom.css" rel="stylesheet" />
     <!-- GOOGLE FONTS-->
   <link href='http://fonts.googleapis.com/css?family=Open+Sans' rel='stylesheet' type='text/css' />

 <script type="text/javascript"
     src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
  </script>


<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    extensions: ["tex2jax.js"],
    jax: ["input/TeX", "output/HTML-CSS"],
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
      processEscapes: true
    },
    "HTML-CSS": { availableFonts: ["TeX"] }
  });
</script>


</head>
<body>
    <div id="wrapper">
        <nav class="navbar navbar-default navbar-cls-top " role="navigation" style="margin-bottom: 0">
            <div class="navbar-header">
                <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".sidebar-collapse">
                    <span class="sr-only">Toggle navigation</span>
                    <span class="icon-bar"></span>
                    <span class="icon-bar"></span>
                    <span class="icon-bar"></span>
                </button>
                <a class="navbar-brand" href="index.html">Binary admin</a> 
            </div>
  <div style="color: white;
padding: 15px 50px 5px 50px;
float: right;
font-size: 16px;"> Last access : 30 May 2014 &nbsp; <a href="#" class="btn btn-danger square-btn-adjust">Logout</a> </div>
        </nav>   
           <!-- /. NAV TOP  -->
                <nav class="navbar-default navbar-side" role="navigation">
            <div class="sidebar-collapse">
                <ul class="nav" id="main-menu">
				<li class="text-center">
                    <img src="assets/img/find_user.png" class="user-image img-responsive"/>
					</li>
				
					
                    <li>
                        <a  href="index.html"><i class="fa fa-dashboard fa-3x"></i> Dashboard</a>
                    </li>
                      <li>
                        <a  href="ui.html"><i class="fa fa-desktop fa-3x"></i> UI Elements</a>
                    </li>
                    <li>
                        <a  href="tab-panel.html"><i class="fa fa-qrcode fa-3x"></i> Tabs & Panels</a>
                    </li>
						   <li  >
                        <a  href="chart.html"><i class="fa fa-bar-chart-o fa-3x"></i> Morris Charts</a>
                    </li>	
                      <li  >
                        <a  href="table.html"><i class="fa fa-table fa-3x"></i> Table Examples</a>
                    </li>
                    <li  >
                        <a  href="form.html"><i class="fa fa-edit fa-3x"></i> Forms </a>
                    </li>				
					
					                   
                    <li>
                        <a href="#"><i class="fa fa-sitemap fa-3x"></i> Multi-Level Dropdown<span class="fa arrow"></span></a>
                        <ul class="nav nav-second-level">
                            <li>
                                <a href="#">Second Level Link</a>
                            </li>
                            <li>
                                <a href="#">Second Level Link</a>
                            </li>
                            <li>
                                <a href="#">Second Level Link<span class="fa arrow"></span></a>
                                <ul class="nav nav-third-level">
                                    <li>
                                        <a href="#">Third Level Link</a>
                                    </li>
                                    <li>
                                        <a href="#">Third Level Link</a>
                                    </li>
                                    <li>
                                        <a href="#">Third Level Link</a>
                                    </li>

                                </ul>
                               
                            </li>
                        </ul>
                      </li>  
                  <li  >
                        <a class="active-menu"  href="blank.html"><i class="fa fa-square-o fa-3x"></i> Blank Page</a>
                    </li>	
                </ul>
               
            </div>
            
        </nav>  
        <!-- /. NAV SIDE  -->
        <div id="page-wrapper" >
            <div id="page-inner">
                <div class="row">
                    <div class="col-md-12">
                     <h2>Blank Page</h2>   
                        <h5>Welcome Jhon Deo , Love to see you back. Welcome Jhon Deo , Love to see you back. Welcome Jhon Deo , Love to see you back. Welcome Jhon Deo , Love to see you back. </h5>
                        
                        home

source

downloads

docs

packages

blog

community

learning

teaching

publications

GSoC

juliacon

2017
June 20th - June 24th 2017, Berkeley, CA. 
Talks and workshops. Tickets.

Julia is part of Google Summer of Code 2017!
Students are working on these 18 projects.Julia is a high-level, high-performance dynamic programming language for numerical computing. It provides a sophisticated compiler, distributed parallel execution, numerical accuracy, and an extensive mathematical function library. Julia’s Base library, largely written in Julia itself, also integrates mature, best-of-breed open source C and Fortran libraries for linear algebra, random number generation, signal processing, and string processing. In addition, the Julia developer community is contributing a number of external packages through Julia’s built-in package manager at a rapid pace. IJulia, a collaboration between the Jupyter and Julia communities, provides a powerful browser-based graphical notebook interface to Julia.
Julia programs are organized around multiple dispatch; by defining functions and overloading them for different combinations of argument types, which can also be user-defined. For a more in-depth discussion of the rationale and advantages of Julia over other systems, see the following highlights or read the introduction in the online manual.
JuliaCon 2016, the annual conference on Julia was held during June 21st - 25th at MIT. Below is a random video from our youtube playlist of the talks. Click on the playlist icon to check out the other videos.
A Summary of Features
Multiple dispatch: providing ability to define function behavior across many combinations of argument types
Dynamic type system: types for documentation, optimization, and dispatch
Good performance, approaching that of statically-compiled languages like C
Built-in package manager
Lisp-like macros and other metaprogramming facilities
Call Python functions: use the PyCall package
Call C functions directly: no wrappers or special APIs
Powerful shell-like capabilities for managing other processes
Designed for parallelism and distributed computation
Coroutines: lightweight “green” threading
User-defined types are as fast and compact as built-ins
Automatic generation of efficient, specialized code for different argument types
Elegant and extensible conversions and promotions for numeric and other types
Efficient support for Unicode, including but not limited to UTF-8
MIT licensed: free and open source
High-Performance JIT CompilerJulia’s LLVM-based just-in-time (JIT) compiler combined with the language’s design allow it to approach and often match the performance of C. To get a sense of relative performance of Julia compared to other languages that can or could be used for numerical and scientific computing, we’ve written a small set of micro-benchmarks in a variety of languages: C, Fortran, Julia, Python, Matlab/Octave, R, JavaScript, Java, Lua, Go, and Mathematica. We encourage you to skim the code to get a sense for how easy or difficult numerical programming in each language is. The following micro-benchmark results were obtained on a single core (serial execution) on an Intel(R) Xeon(R) CPU E7-8850 2.00GHz CPU with 1TB of 1067MHz DDR3 RAM, running Linux:
FortranJuliaPythonRMatlabOctaveMathe-maticaJavaScriptGoLuaJITJava
gcc 5.1.10.4.03.4.33.2.2R2015b4.0.010.2.0V8 3.28.71.19go1.5gsl-shell 2.3.11.8.0_45fib0.702.1177.76533.5226.899324.35118.533.361.861.711.21
parse_int5.051.4517.0245.73802.529581.4415.026.061.205.773.35
quicksort1.311.1532.89264.544.921866.0143.232.701.292.032.60
mandel0.810.7915.3253.167.58451.815.130.661.110.671.35
pi_sum1.001.0021.999.561.00299.311.691.011.001.001.00
rand_mat_stat1.451.6617.9314.5614.5230.935.952.302.963.273.92
rand_mat_mul3.481.021.141.571.121.121.3015.071.421.162.36Figure: benchmark times relative to C (smaller is better, C performance = 1.0).
C and Fortran compiled by gcc 5.1.1, taking best timing from all optimization levels (-O0 through -O3). C, Fortran, Go, and Julia use OpenBLAS v0.2.14. Python 3 was installed from the Anaconda distribution. The Python implementations of rand_mat_stat and rand_mat_mul use NumPy (v1.9.2) functions; the rest are pure Python implementations.
Benchmarks can also be seen here as a plot created with Gadfly.
These benchmarks, while not comprehensive, do test compiler performance on a range of common code patterns, such as function calls, string parsing, sorting, numerical loops, random number generation, and array operations. It is important to note that these benchmark implementations are not written for absolute maximal performance (the fastest code to compute fib(20) is the constant literal 6765). Rather, all of the benchmarks are written to test the performance of specific algorithms implemented in each language. In particular, all languages use the same algorithm: the Fibonacci benchmarks are all recursive while the pi summation benchmarks are all iterative; the “algorithm” for random matrix multiplication is to call the most obvious built-in/standard random-number and matmul routines (or to directly call BLAS if the language does not provide a high-level matmul), except where a matmul/BLAS call is not possible (such as in JavaScript). The point of these benchmarks is to compare the performance of specific algorithms across language implementations, not to compare the fastest means of computing a result, which in most high-level languages relies on calling C code. Raw benchmark numbers in CSV format are available here.
To give a quick taste of what Julia looks like, here is the code used in the Mandelbrot and random matrix statistics benchmarks:
function mandel(z) c = z maxiter = 80 for n = 1:maxiter if abs(z) > 2 return n-1 end z = z^2 + c end return maxiter end function randmatstat(t) n = 5 v = zeros(t) w = zeros(t) for i = 1:t a = randn(n,n) b = randn(n,n) c = randn(n,n) d = randn(n,n) P = [a b c d] Q = [a b; c d] v[i] = trace((P.'*P)^4) w[i] = trace((Q.'*Q)^4) end std(v)/mean(v), std(w)/mean(w) end​ The code above is quite clear, and should feel familiar to anyone who has programmed in other mathematical languages. The Julia implementation of randmatstat is considerably simpler than the equivalent C implementation, without giving up much performance. Planned compiler optimizations will close this performance gap in the future. By design, Julia allows you to range from tight low-level loops, up to a high-level programming style, while sacrificing some performance, but gaining the ability to express complex algorithms easily. This continuous spectrum of programming levels is a hallmark of the Julia approach to programming and is very much an intentional feature of the language.
Designed for Parallelism and Cloud ComputingJulia does not impose any particular style of parallelism on the user. Instead, it provides a number of key building blocks for distributed computation, making it flexible enough to support a number of styles of parallelism, and allowing users to add more. The following simple example demonstrates how to count the number of heads in a large number of coin tosses in parallel.
nheads = @parallel (+) for i=1:100000000 rand(Bool) endThis computation is automatically distributed across all available compute nodes, and the result, reduced by summation (+), is returned at the calling node.
Here is a screenshot of a web-based interactive IJulia Notebook session, using Gadfly. JuliaBox provides a way to run IJulia notebooks in your browser on Docker sandboxed containers provisioned on demand.


This paves the way for fully cloud-based operation, including data management, code editing and sharing, execution, debugging, collaboration, analysis, data exploration, and visualization. The eventual goal is to let people stop worrying about administering machines and managing data and get straight to the real problem.
Gadfly can produce various plots with various rendering backends in the browser (SVG, PDF, PNG and various other backends are also supported). Interactivity can be added to graphs and plots with the Interact.jl package. A small sampling of the capabilities of Gadfly is presented below.


Free, Open Source and Library-FriendlyThe core of the Julia implementation is licensed under the MIT license. Various libraries used by the Julia environment include their own licenses such as the GPL, LGPL, and BSD (therefore the environment, which consists of the language, user interfaces, and libraries, is under the GPL). The language can be built as a shared library, so users can combine Julia with their own C/Fortran code or proprietary third-party libraries. Furthermore, Julia makes it simple to call external functions in C and Fortran shared libraries, without writing any wrapper code or even recompiling existing code. You can try calling external library functions directly from Julia’s interactive prompt, getting immediate feedback. See LICENSE for the full terms of Julia’s licensing.
Julia is a NumFocus project. We thank Fastly for their generous infrastructural support. Edit this page on GitHub.
Donate Now
English
​

Let $\chi_3$ be the non-principal Dirichlet character of period $3$ (thus $\chi_3(n)$ equals $+1$ when $n=1 \ (3)$, $-1$ when $n = 2 \ (3)$, and $0$ when $n = 0 \ (3)$), and define the completely multiplicative function $\tilde \chi_3\colon \mathbb N \to \{-1,+1\}$ by setting $\tilde \chi_3(p) := \chi_3(p)$ when $p \neq 3$ and $\tilde \chi_3(3) = +1$. This is about the simplest modification one can make to Example to eliminate the zeroes. Now consider the sum$$ \sum_{j=1}^n \tilde \chi_3(j)$$with $n := 1 + 3 + 3^2 + \dots + 3^k$ for some large $k$. Writing $j = 3^i m$ with $m$ coprime to $3$ and $i$ at most $k$, we can write this sum as$$ \sum_{i=0}^k \sum_{1 \leq m \leq n/3^j: (m,3)=1} \tilde \chi_3(3^i m).$$Now observe that $\tilde \chi_3(3^i m) = \tilde \chi_3(3)^i \tilde \chi_3(m) = \chi_3(m)$. The function $\chi_3$ has mean zero on every interval of length three, and $\lfloor n/3^j\rfloor$ is equal to $1$ mod $3$, hence$$ \sum_{1 \leq m \leq n/3^j: (m,3)=1} \tilde \chi_3(3^i m) = 1$$for every $i=0,\dots,k$. Summing in $i$, we conclude that$$ \sum_{j=1}^n \tilde \chi_3(j) = k+1 \gg \log n.$$More generally, for natural numbers $n$, $\sum_{j=1}^n \tilde \chi_3(j)$ is equal to the number of $1$s in the base $3$ expansion of $n$. ​Thus $\tilde \chi_3$ has infinite discrepancy, but the divergence is only logarithmic in the $n$ parameter; indeed from the above calculations and the complete multiplicativity of $\tilde \chi_3$ we see that $\sup_{n \leq N; d \in \mathbb N} \left| \sum_{j=1}^n \tilde \chi_3(jd)\right|$ is comparable to $\log N$ for $N>1$. This can be compared with random sequences $f\colon \mathbb N \to \{-1,+1\}$, whose discrepancy would be expected to diverge like $N^{1/2+o(1)}$. See the paper of Borwein, Choi, and Coons for further analysis of functions such as $\tilde \chi_3$, which seems to have been first discussed in; see also for some further discussion of the sign patterns in $\tilde \chi_3$. One can also reduce the discrepancy of this example slightly (by a factor of about two) by changing the value of the completely multiplicative function $\tilde \chi_3$ at $3$ from $+1$ to $-1$.

 
​First we construct a fundamental solution to $\Delta u+k^2u=0$ in $\mathbb R^3-\{0\}$ by considering radially symmetric solutions $u(x)=v(\left|x\right|)=v(r)$. We can easily calculate to have that $v$ satisfies the following equation\[v''+\frac{2}{r}v'+k^2v=0.\]The general solution to this equation is\[v(r) = \frac{{{c_1}\cos (kr)}}{r} + \frac{{{c_2}\sin (kr)}}{r},\;\text{for some constants }c_1,\;c_2.\]By choosing $c_1=-1/(4\pi)$ and $c_2=0$, we recover the function $w$ as defined before.

Consider \[u(x) = \int_{{\mathbb R^3}} {w(x - y)f(y)dy}  = \int_{{\mathbb R^3}} {w(y)f(x - y)dy} .\]First we show that $u$ is twice continuously differentiable. We have that \[\frac{{u(x + h{e_i}) - u(x)}}{h} = \int_{{\mathbb R^3}} {w(y)\frac{{f(x + h{e_i} - y) - f(x - y)}}{y}dy} ,\]for $h\neq 0$, $e_i$ is a coordinate vector. But \[\frac{{f(x + h{e_i} - y) - f(x - y)}}{y} \to {f_{{x_i}}}(x - y)\]uniformly as $h\to 0,$ and thus \[{u_{{x_i}}}(x) = \int_{\mathbb R^3} {w(y){f_{{x_i}}}(x - y)dy} .\]Similarly we can get the expression for second derivatives of $u$. As the right-hand side is continuous in $x$, we see that $u$ is twice continuously differentiable.\\
In the next stage, we need to show $(\Delta +k^2)u(x)=f(x)$ for every $x\in \mathbb R^3$. By using the same techniques as in solving the Poisson's equation, we fix $\varepsilon >0$ and consider\[\begin{aligned}\Delta u(x)& = \int_{ B(0,\varepsilon )} {w(y){\Delta _x}f(x - y)dy}  + \int_{{\mathbb R^3} -B(0,\varepsilon )} {w(y)f(x - y)dy} \\&=:I_{\varepsilon}+J_{\varepsilon}.\end{aligned}\]Now\[\begin{aligned}\left| {{I_\varepsilon }} \right| \le C{\left\| {{D^2}f} \right\|_{{L^\infty }({\mathbb R^3})}}\int_{B(0,\varepsilon )} {\left| {w(y)} \right|dy} & \le C{\left\| {{D^2}f} \right\|_{{L^\infty }({\mathbb R^3})}}\int_{B(0,\varepsilon )} {\frac{{\left| {\cos (k\left| y \right|)} \right|}}{{\left| y \right|}}dy} \\&\le C{\left\| {{D^2}f} \right\|_{{L^\infty }({\mathbb R^3})}}\int_{B(0,\varepsilon )} {\frac{1}{{\left| y \right|}}dy}  \le C{\varepsilon ^2},\end{aligned}\]for some universal constant $C$.

Since $f$ has compact support and $\Delta _xf(x-y)=\Delta _yf(x-y)$, using integration by parts on $J_{\varepsilon}$ yields
\[\begin{aligned}{J_\varepsilon }& =  - \int_{{\mathbb R^3} - B(0,\varepsilon )} {Dw(y)\cdot{D_y}f(x - y)dy}  + \int_{\partial B(0,\varepsilon )} {w(y)\frac{{\partial f}}{{\partial \nu}}(x - y)dS(y)},\\&=:K_{\varepsilon}+L_{\varepsilon},\end{aligned}\]with $\nu$ denoting the inward pointing unit normal along $\partial B(0,\varepsilon)$. Estimating $L_{\varepsilon}$ we have that\[\left| {{L_\varepsilon }} \right| \le C{\left\| {Df} \right\|_{{L^\infty }({\mathbb R^3})}}\int_{\partial B(0,\varepsilon )} {\left| {w(y)} \right|dS(y)}  \le C{\left\| {Df} \right\|_{{L^\infty }({\mathbb R^3})}}\int_{\partial B(0,\varepsilon )} {\frac{1}{{\left| y \right|}}dS(y)}  \le C\varepsilon .\]To summarize, we have that\[\Delta u(x)=I_{\varepsilon}+K_{\varepsilon}+L_{\varepsilon},\]
with $I_{\varepsilon}\to 0$ and $L_{\varepsilon}\to 0$ as $\varepsilon \to 0$. Hence, we need to show that$K_{\varepsilon}+k^2u(x)\to f(x)\text{ as }\varepsilon \to 0.$
Integrating by parts once again in $K_{\varepsilon}$, we get\[\begin{aligned}{K_\varepsilon }& = \int_{{\mathbb R^3} - B(0,\varepsilon )} {\Delta w(y)f(x - y)dy}  - \int_{\partial B(0,\varepsilon )} {\frac{{\partial w}}{{\partial \nu}}(y)f(x - y)dS(y)} \\&=  - \int_{{\mathbb R^3} - B(0,\varepsilon )} {{k^2}w(y)f(x - y)dy}  - \int_{\partial B(0,\varepsilon )} {\frac{{\partial w}}{{\partial \nu}}(y)f(x - y)dS(y)},\end{aligned}\]since $\Delta w =-k^2w$ away from the origin. The first term when added $k^2u$ will tend to $0$ because
\[ - \int_{{\mathbb R^3} - B(0,\varepsilon )} {{k^2}w(y)f(x - y)dy}  + {k^2}u(y) = \int_{B(0,\varepsilon )} {{k^2}w(y)f(x - y)dy} \mathop  \to  0 \;\;\text{ as }\varepsilon \to 0.\]To compute the second term, we notice that\[Dw(y) = \frac{1}{{4\pi }}\cdot\frac{{k\sin (k\left| y \right|) + \cos (k\left| y \right|)}}{{{{\left| y \right|}^3}}} y\quad \text{ and }\quad \nu = \frac{{ - y}}{{\left| y \right|}}.\]
Consequently on $\partial B(0,\varepsilon)$ we have that
\[\frac{{\partial w}}{{\partial \nu}}(y) = \nu\cdot Dw(y) =  - \frac{1}{{4\pi }}\cdot\frac{{k\sin (k\varepsilon ) + \cos (k\varepsilon )}}{{{\varepsilon ^2}}}.\]

 
​First we construct a fundamental solution to $\Delta u+k^2u=0$ in $\mathbb R^3-\{0\}$ by considering radially symmetric solutions $u(x)=v(\left|x\right|)=v(r)$. We can easily calculate to have that $v$ satisfies the following equation\[v''+\frac{2}{r}v'+k^2v=0.\]The general solution to this equation is\[v(r) = \frac{{{c_1}\cos (kr)}}{r} + \frac{{{c_2}\sin (kr)}}{r},\;\text{for some constants }c_1,\;c_2.\]By choosing $c_1=-1/(4\pi)$ and $c_2=0$, we recover the function $w$ as defined before.

Consider \[u(x) = \int_{{\mathbb R^3}} {w(x - y)f(y)dy}  = \int_{{\mathbb R^3}} {w(y)f(x - y)dy} .\]First we show that $u$ is twice continuously differentiable. We have that \[\frac{{u(x + h{e_i}) - u(x)}}{h} = \int_{{\mathbb R^3}} {w(y)\frac{{f(x + h{e_i} - y) - f(x - y)}}{y}dy} ,\]for $h\neq 0$, $e_i$ is a coordinate vector. But \[\frac{{f(x + h{e_i} - y) - f(x - y)}}{y} \to {f_{{x_i}}}(x - y)\]uniformly as $h\to 0,$ and thus \[{u_{{x_i}}}(x) = \int_{\mathbb R^3} {w(y){f_{{x_i}}}(x - y)dy} .\]Similarly we can get the expression for second derivatives of $u$. As the right-hand side is continuous in $x$, we see that $u$ is twice continuously differentiable.\\
In the next stage, we need to show $(\Delta +k^2)u(x)=f(x)$ for every $x\in \mathbb R^3$. By using the same techniques as in solving the Poisson's equation, we fix $\varepsilon >0$ and consider\[\begin{aligned}\Delta u(x)& = \int_{ B(0,\varepsilon )} {w(y){\Delta _x}f(x - y)dy}  + \int_{{\mathbb R^3} -B(0,\varepsilon )} {w(y)f(x - y)dy} \\&=:I_{\varepsilon}+J_{\varepsilon}.\end{aligned}\]Now\[\begin{aligned}\left| {{I_\varepsilon }} \right| \le C{\left\| {{D^2}f} \right\|_{{L^\infty }({\mathbb R^3})}}\int_{B(0,\varepsilon )} {\left| {w(y)} \right|dy} & \le C{\left\| {{D^2}f} \right\|_{{L^\infty }({\mathbb R^3})}}\int_{B(0,\varepsilon )} {\frac{{\left| {\cos (k\left| y \right|)} \right|}}{{\left| y \right|}}dy} \\&\le C{\left\| {{D^2}f} \right\|_{{L^\infty }({\mathbb R^3})}}\int_{B(0,\varepsilon )} {\frac{1}{{\left| y \right|}}dy}  \le C{\varepsilon ^2},\end{aligned}\]for some universal constant $C$.



Since $f$ has compact support and $\Delta _xf(x-y)=\Delta _yf(x-y)$, using integration by parts on $J_{\varepsilon}$ yields
\[\begin{aligned}{J_\varepsilon }& =  - \int_{{\mathbb R^3} - B(0,\varepsilon )} {Dw(y)\cdot{D_y}f(x - y)dy}  + \int_{\partial B(0,\varepsilon )} {w(y)\frac{{\partial f}}{{\partial \nu}}(x - y)dS(y)},\\&=:K_{\varepsilon}+L_{\varepsilon},\end{aligned}\]with $\nu$ denoting the inward pointing unit normal along $\partial B(0,\varepsilon)$. Estimating $L_{\varepsilon}$ we have that\[\left| {{L_\varepsilon }} \right| \le C{\left\| {Df} \right\|_{{L^\infty }({\mathbb R^3})}}\int_{\partial B(0,\varepsilon )} {\left| {w(y)} \right|dS(y)}  \le C{\left\| {Df} \right\|_{{L^\infty }({\mathbb R^3})}}\int_{\partial B(0,\varepsilon )} {\frac{1}{{\left| y \right|}}dS(y)}  \le C\varepsilon .\]To summarize, we have that\[\Delta u(x)=I_{\varepsilon}+K_{\varepsilon}+L_{\varepsilon},\]
with $I_{\varepsilon}\to 0$ and $L_{\varepsilon}\to 0$ as $\varepsilon \to 0$. Hence, we need to show that$K_{\varepsilon}+k^2u(x)\to f(x)\text{ as }\varepsilon \to 0.$
Integrating by parts once again in $K_{\varepsilon}$, we get\[\begin{aligned}{K_\varepsilon }& = \int_{{\mathbb R^3} - B(0,\varepsilon )} {\Delta w(y)f(x - y)dy}  - \int_{\partial B(0,\varepsilon )} {\frac{{\partial w}}{{\partial \nu}}(y)f(x - y)dS(y)} \\&=  - \int_{{\mathbb R^3} - B(0,\varepsilon )} {{k^2}w(y)f(x - y)dy}  - \int_{\partial B(0,\varepsilon )} {\frac{{\partial w}}{{\partial \nu}}(y)f(x - y)dS(y)},\end{aligned}\]since $\Delta w =-k^2w$ away from the origin. The first term when added $k^2u$ will tend to $0$ because
\[ - \int_{{\mathbb R^3} - B(0,\varepsilon )} {{k^2}w(y)f(x - y)dy}  + {k^2}u(y) = \int_{B(0,\varepsilon )} {{k^2}w(y)f(x - y)dy} \mathop  \to  0 \;\;\text{ as }\varepsilon \to 0.\]To compute the second term, we notice that\[Dw(y) = \frac{1}{{4\pi }}\cdot\frac{{k\sin (k\left| y \right|) + \cos (k\left| y \right|)}}{{{{\left| y \right|}^3}}} y\quad \text{ and }\quad \nu = \frac{{ - y}}{{\left| y \right|}}.\]
Consequently on $\partial B(0,\varepsilon)$ we have that
\[\frac{{\partial w}}{{\partial \nu}}(y) = \nu\cdot Dw(y) =  - \frac{1}{{4\pi }}\cdot\frac{{k\sin (k\varepsilon ) + \cos (k\varepsilon )}}{{{\varepsilon ^2}}}.\]
​​

Người đá cặp bên cạnh Xuân Trường là Đông Triều cũng gây ấn tượng không chỉ ở khả năng ngăn chặn Macau phản công mà còn có những đường chuyền khó chịu vào sau lưng hàng thủ đối phương. Từ một pha bóng như vậy, Đông Triều đã kiến tạo cho đồng đội ở HAGL là Hồng Duy ghi bàn ngay sau khi vào sân đầu hiệp hai.

Trong suốt nửa cuối hiệp hai, Việt Nam vẫn ép sân và tạo ra vô số cơ hội. Tuy nhiên các chân sút chủ nhà thiếu đi sự chính xác cần thiết để có được thêm bàn thắng.

Đánh bại Macau giúp Việt Nam giành ngôi đầu bảng I bởi Hàn Quốc bất ngờ bị Đông Timor cầm hòa 0-0 trước đó. Ở lượt đấu cuối, nếu các học trò của HLV Hữu Thắng không thua Hàn Quốc thì sẽ giành vé trực tiếp tới giải U23 châu Á 2018.

Tuy nhiên nếu để thua Hàn Quốc thì Việt Nam sẽ phải chờ đợi những đối thủ xếp nhì ở chín bảng còn lại. Năm đội nhì bảng có thành tích tốt nhất sẽ giành quyền tới Trung Quốc vào năm sau. 
​​​
                       
                    </div>
                    <!-- HTML generated using hilite.me --><div style="background: #272822; overflow:auto;width:auto;border:solid gray;border-width:.1em .1em .1em .8em;padding:.2em .6em;"><pre style="margin: 0; line-height: 125%"><span style="color: #66d9ef">def</span> <span style="color: #a6e22e">h</span><span style="color: #f8f8f2">(w,</span> <span style="color: #f8f8f2">x):</span>    
    <span style="color: #66d9ef">return</span> <span style="color: #f8f8f2">np</span><span style="color: #f92672">.</span><span style="color: #f8f8f2">sign(np</span><span style="color: #f92672">.</span><span style="color: #f8f8f2">dot(w</span><span style="color: #f92672">.</span><span style="color: #f8f8f2">T,</span> <span style="color: #f8f8f2">x))</span>

<span style="color: #66d9ef">def</span> <span style="color: #a6e22e">has_converged</span><span style="color: #f8f8f2">(X,</span> <span style="color: #f8f8f2">y,</span> <span style="color: #f8f8f2">w):</span>    
    <span style="color: #66d9ef">return</span> <span style="color: #f8f8f2">np</span><span style="color: #f92672">.</span><span style="color: #f8f8f2">array_equal(h(w,</span> <span style="color: #f8f8f2">X),</span> <span style="color: #f8f8f2">y)</span> 

<span style="color: #66d9ef">def</span> <span style="color: #a6e22e">perceptron</span><span style="color: #f8f8f2">(X,</span> <span style="color: #f8f8f2">y,</span> <span style="color: #f8f8f2">w_init):</span>
    <span style="color: #f8f8f2">w</span> <span style="color: #f92672">=</span> <span style="color: #f8f8f2">[w_init]</span>
    <span style="color: #f8f8f2">N</span> <span style="color: #f92672">=</span> <span style="color: #f8f8f2">X</span><span style="color: #f92672">.</span><span style="color: #f8f8f2">shape[</span><span style="color: #ae81ff">1</span><span style="color: #f8f8f2">]</span>
    <span style="color: #f8f8f2">d</span> <span style="color: #f92672">=</span> <span style="color: #f8f8f2">X</span><span style="color: #f92672">.</span><span style="color: #f8f8f2">shape[</span><span style="color: #ae81ff">0</span><span style="color: #f8f8f2">]</span>
    <span style="color: #f8f8f2">mis_points</span> <span style="color: #f92672">=</span> <span style="color: #f8f8f2">[]</span>
    <span style="color: #66d9ef">while</span> <span style="color: #f8f8f2">True:</span>
        <span style="color: #75715e"># mix data </span>
        <span style="color: #f8f8f2">mix_id</span> <span style="color: #f92672">=</span> <span style="color: #f8f8f2">np</span><span style="color: #f92672">.</span><span style="color: #f8f8f2">random</span><span style="color: #f92672">.</span><span style="color: #f8f8f2">permutation(N)</span>
        <span style="color: #66d9ef">for</span> <span style="color: #f8f8f2">i</span> <span style="color: #f92672">in</span> <span style="color: #f8f8f2">range(N):</span>
            <span style="color: #f8f8f2">xi</span> <span style="color: #f92672">=</span> <span style="color: #f8f8f2">X[:,</span> <span style="color: #f8f8f2">mix_id[i]]</span><span style="color: #f92672">.</span><span style="color: #f8f8f2">reshape(d,</span> <span style="color: #ae81ff">1</span><span style="color: #f8f8f2">)</span>
            <span style="color: #f8f8f2">yi</span> <span style="color: #f92672">=</span> <span style="color: #f8f8f2">y[</span><span style="color: #ae81ff">0</span><span style="color: #f8f8f2">,</span> <span style="color: #f8f8f2">mix_id[i]]</span>
            <span style="color: #66d9ef">if</span> <span style="color: #f8f8f2">h(w[</span><span style="color: #f92672">-</span><span style="color: #ae81ff">1</span><span style="color: #f8f8f2">],</span> <span style="color: #f8f8f2">xi)[</span><span style="color: #ae81ff">0</span><span style="color: #f8f8f2">]</span> <span style="color: #f92672">!=</span> <span style="color: #f8f8f2">yi:</span> <span style="color: #75715e"># misclassified point</span>
                <span style="color: #f8f8f2">mis_points</span><span style="color: #f92672">.</span><span style="color: #f8f8f2">append(mix_id[i])</span>
                <span style="color: #f8f8f2">w_new</span> <span style="color: #f92672">=</span> <span style="color: #f8f8f2">w[</span><span style="color: #f92672">-</span><span style="color: #ae81ff">1</span><span style="color: #f8f8f2">]</span> <span style="color: #f92672">+</span> <span style="color: #f8f8f2">yi</span><span style="color: #f92672">*</span><span style="color: #f8f8f2">xi</span> 
                <span style="color: #f8f8f2">w</span><span style="color: #f92672">.</span><span style="color: #f8f8f2">append(w_new)</span>
                
        <span style="color: #66d9ef">if</span> <span style="color: #f8f8f2">has_converged(X,</span> <span style="color: #f8f8f2">y,</span> <span style="color: #f8f8f2">w[</span><span style="color: #f92672">-</span><span style="color: #ae81ff">1</span><span style="color: #f8f8f2">]):</span>
            <span style="color: #66d9ef">break</span>
    <span style="color: #66d9ef">return</span> <span style="color: #f8f8f2">(w,</span> <span style="color: #f8f8f2">mis_points)</span>

<span style="color: #f8f8f2">d</span> <span style="color: #f92672">=</span> <span style="color: #f8f8f2">X</span><span style="color: #f92672">.</span><span style="color: #f8f8f2">shape[</span><span style="color: #ae81ff">0</span><span style="color: #f8f8f2">]</span>
<span style="color: #f8f8f2">w_init</span> <span style="color: #f92672">=</span> <span style="color: #f8f8f2">np</span><span style="color: #f92672">.</span><span style="color: #f8f8f2">random</span><span style="color: #f92672">.</span><span style="color: #f8f8f2">randn(d,</span> <span style="color: #ae81ff">1</span><span style="color: #f8f8f2">)</span>
<span style="color: #f8f8f2">(w,</span> <span style="color: #f8f8f2">m)</span> <span style="color: #f92672">=</span> <span style="color: #f8f8f2">perceptron(X,</span> <span style="color: #f8f8f2">y,</span> <span style="color: #f8f8f2">w_init)</span>
</pre></div>

                </div>
                 <!-- /. ROW  -->
                 <hr />
               
    			</div>
              
            </div>
          
        </div>
     <!-- /. WRAPPER  -->
    <!-- SCRIPTS -AT THE BOTOM TO REDUCE THE LOAD TIME-->
    <!-- JQUERY SCRIPTS -->
    <script src="assets/js/jquery-1.10.2.js"></script>
      <!-- BOOTSTRAP SCRIPTS -->
    <script src="assets/js/bootstrap.min.js"></script>
    <!-- METISMENU SCRIPTS -->
    <script src="assets/js/jquery.metisMenu.js"></script>
      <!-- CUSTOM SCRIPTS -->
    <script src="assets/js/custom.js"></script>
    
   
</body>
</html>
